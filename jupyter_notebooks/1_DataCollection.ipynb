{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f14624a",
   "metadata": {},
   "source": [
    "# **TradeCare: Data Collection Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b7702",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "* Fetch historical Bitcoin OHLCV (Open, High, Low, Close, Volume) data from a GitHub-hosted repository that provides automated daily updates.\n",
    "* Verify data loaded correctly (basic checks)\n",
    "Verify data loaded correctly (basic quality checks)\n",
    "* Understand data structure and characteristics\n",
    "* Document data source and live data collection strategy\n",
    "## Inputs\n",
    "\n",
    "*  **Data Source:** GitHub Repository (automated updates)\n",
    "*   **URL:** https://raw.githubusercontent.com/mouadja02/bitcoin-hourly-ohclv-dataset/main/btc-hourly-price_2015_2025.csv\\n\",\n",
    "*   **Asset:** BTC-USD\n",
    "*   **Timeframe:** 1 Hour\n",
    "*   **Period:** November 2014 - present\n",
    "\n",
    "## Outputs\n",
    "* DataFrame loaded in memory for exploration\n",
    "* Data understanding documented\n",
    "* Live data approach: No CSV files saved (subsequent notebooks fetch fresh) \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "This GitHub dataset provides a **unique combination** rarely found in ML projects:\n",
    "\n",
    "* **Fresh & Maintained:** Automated workflow fetches current data from CryptoCompare API daily and stores backups on GitHub. Repository contains Bitcoin hourly price data from 2015 to present with continuous updates\n",
    "* **Simple**: Direct CSV access via single URL\n",
    "* **Free**: No API keys or costs  \n",
    "* **Reliable**: No rate limits or auth failures  \n",
    "* **Transparent**: Git history shows every change  \n",
    "* **Scalable**: Should work in production environments  \n",
    "\n",
    "**Live Data Strategy:**\n",
    "* This notebook fetches data from URL and explores it\n",
    "* No CSV files are saved (live data approach)\n",
    "* Each notebook in the pipeline will fetch fresh data as needed\n",
    "* This ensures always up-to-date analysis and predictions\n",
    "* Trade-off: Requires internet connection, slightly slower but more current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21778133",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ca8ca",
   "metadata": {},
   "source": [
    "## Change Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2f33d",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with `os.getcwd()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a21e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ilianamarquez/Documents/vscode-projects/trade-care/jupyter_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd609a",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e01b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3793eff",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09525469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ilianamarquez/Documents/vscode-projects/trade-care'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb167f",
   "metadata": {},
   "source": [
    "# Fetch Data from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824cfea",
   "metadata": {},
   "source": [
    "Import Required Libraries       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8295c97",
   "metadata": {},
   "source": [
    "## Define Data Source   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5f8e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Source: https://raw.githubusercontent.com/mouadja02/bitcoin-hourly-ohclv-dataset/main/btc-hourly-price_2015_2025.csv\n",
      "Live data approach: Fetching fresh data directly from GitHub\n"
     ]
    }
   ],
   "source": [
    "# GitHub raw CSV URL\n",
    "data_url = \"https://raw.githubusercontent.com/mouadja02/bitcoin-hourly-ohclv-dataset/main/btc-hourly-price_2015_2025.csv\"\n",
    "\n",
    "print(f\"Data Source: {data_url}\")\n",
    "print(\"Live data approach: Fetching fresh data directly from GitHub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1b8be",
   "metadata": {},
   "source": [
    "## Download Data from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fd7166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Bitcoin hourly data from GitHub...\n",
      "✓ Data fetched successfully\n",
      "✓ Shape: 96,570 rows × 9 columns\n"
     ]
    }
   ],
   "source": [
    "# Fetch the CSV file directly into DataFrame\n",
    "print(\"Fetching Bitcoin hourly data from GitHub...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_url)\n",
    "    \n",
    "    print(f\"✓ Data fetched successfully\")\n",
    "    print(f\"✓ Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error fetching data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9f0fd",
   "metadata": {},
   "source": [
    "## Validate Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02075311",
   "metadata": {},
   "source": [
    "# Data validation for security and integrity\n",
    "print(\"Validating data structure and integrity...\")\n",
    "\n",
    "# Expected structure validation (actual column names from dataset)\n",
    "expected_columns = ['TIME_UNIX', 'DATE_STR', 'HOUR_STR', 'OPEN_PRICE', \n",
    "                   'HIGH_PRICE', 'CLOSE_PRICE', 'LOW_PRICE', 'VOLUME_FROM', 'VOLUME_TO']\n",
    "\n",
    "# Check if expected columns exist\n",
    "missing_cols = [col for col in expected_columns if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing expected columns: {missing_cols}\")\n",
    "\n",
    "print(f\"✓ All {len(expected_columns)} columns present\")\n",
    "\n",
    "# Validate data ranges (security check)\n",
    "price_columns = ['OPEN_PRICE', 'HIGH_PRICE', 'LOW_PRICE', 'CLOSE_PRICE']\n",
    "for col in price_columns:\n",
    "    if df[col].min() < 0:\n",
    "        raise ValueError(f\"Invalid data: {col} contains negative values\")\n",
    "    if df[col].max() > 500000:  # BTC unlikely > $500k in 2025\n",
    "        raise ValueError(f\"Suspicious data: {col} contains values > $500k\")\n",
    "\n",
    "print(\"✓ Price ranges validated (all positive, < $500k)\")\n",
    "\n",
    "# Validate reasonable row count (2015-2025 = ~10 years = ~87,600 hours)\n",
    "if len(df) < 96570\n",
    "    raise ValueError(f\"Unexpected row count: {len(df):,}. Expected > 69570 rows\")\n",
    "\n",
    "print(f\"✓ Row count reasonable: {len(df):,} rows\")\n",
    "\n",
    "# Validate timestamp column\n",
    "if df['TIME_UNIX'].min() < 1416031200:  # Before 2014-11-15, 1st entry of our desired dataset\n",
    "    raise ValueError(\"Timestamps before 2015 detected\")\n",
    "\n",
    "print(\"Timestamps validated\")\n",
    "print(\"\\n All data validation checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393fc607",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d362e5c",
   "metadata": {},
   "source": [
    "## Validate Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138b9ed",
   "metadata": {},
   "source": [
    "## Load CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229628e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the downloaded data\n",
    "df = pd.read_csv(f\"{destination_folder}/bitcoin_hourly_raw.csv\")\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3baf580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99c0cd65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f7611",
   "metadata": {},
   "source": [
    "NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cf58b",
   "metadata": {},
   "source": [
    "* You may add as many sections as you want, as long as it supports your project workflow.\n",
    "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eecfbd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb6028",
   "metadata": {},
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e8683",
   "metadata": {},
   "source": [
    "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  # create here your folder\n",
    "  # os.makedirs(name='')\n",
    "except Exception as e:\n",
    "  print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
